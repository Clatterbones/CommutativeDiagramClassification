{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65c1f28",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Binary classification of commutative diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b087f593",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import torch\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import mnist\n",
    "import tensorflow_addons as tfa # Needed for Yogi optimizer\n",
    "tfa.register_all(custom_kernels=False) # Registers TFA objects in TF dictionaries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b277ca83-a21c-4c3c-94be-37b7b52af9cb",
   "metadata": {},
   "source": [
    "## 1. Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbf2aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 Expand working directory with train, test and validation folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551ef7f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "unsortedSamplesDirName = 'diagramSamplesMarch25'\n",
    "##\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "unsortedSamplesDir = os.path.join(cwd, unsortedSamplesDirName)\n",
    "assert('positive' in os.listdir(unsortedSamplesDir) and 'negative' in os.listdir(unsortedSamplesDir))\n",
    "unsortedPositiveSamplesDir = os.path.join(unsortedSamplesDir, 'positive')\n",
    "unsortedNegativeSamplesDir = os.path.join(unsortedSamplesDir, 'negative')\n",
    "\n",
    "sortedSamplesDir = os.path.join(cwd, 'sortedSamples')\n",
    "os.makedirs(sortedSamplesDir, exist_ok=True)\n",
    "\n",
    "trainDir = os.path.join(sortedSamplesDir, 'train')\n",
    "testDir = os.path.join(sortedSamplesDir, 'test')\n",
    "valDir = os.path.join(sortedSamplesDir, 'val')\n",
    "os.makedirs(trainDir, exist_ok=True)\n",
    "os.makedirs(testDir, exist_ok=True)\n",
    "os.makedirs(valDir, exist_ok=True)\n",
    "\n",
    "trainPositiveDir = os.path.join(trainDir, 'positive')\n",
    "trainNegativeDir = os.path.join(trainDir, 'negative')\n",
    "testPositiveDir = os.path.join(testDir, 'positive')\n",
    "testNegativeDir = os.path.join(testDir, 'negative')\n",
    "valPositiveDir = os.path.join(valDir, 'positive')\n",
    "valNegativeDir = os.path.join(valDir, 'negative')\n",
    "os.makedirs(trainPositiveDir, exist_ok=True)\n",
    "os.makedirs(trainNegativeDir, exist_ok=True)\n",
    "os.makedirs(testPositiveDir, exist_ok=True)\n",
    "os.makedirs(testNegativeDir, exist_ok=True)\n",
    "os.makedirs(valPositiveDir, exist_ok=True)\n",
    "os.makedirs(valNegativeDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3344b2e-0d63-41d6-aafa-eac29f9b7005",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 Copy images into folders\n",
    "The code currently randomly truncates the greater partition between positive and negative to achieve parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8afd1c9-8b49-43ba-83b9-e9c9588b7788",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "trainRatio = 0.6\n",
    "testRatio = 0.2\n",
    "valRatio = 0.2\n",
    "assert(trainRatio + testRatio + valRatio == 1.)\n",
    "\n",
    "positiveRatio = 0.5 # Desired ratio of positive samples in the sorted data\n",
    "\n",
    "performCopy = False\n",
    "##\n",
    "\n",
    "if performCopy:\n",
    "    positiveSamplesFilenameList = os.listdir(unsortedPositiveSamplesDir)\n",
    "    negativeSamplesFilenameList = os.listdir(unsortedNegativeSamplesDir)\n",
    "    random.shuffle(positiveSamplesFilenameList)\n",
    "    random.shuffle(negativeSamplesFilenameList)\n",
    "    numPositiveSamples = len(positiveSamplesFilenameList)\n",
    "    numNegativeSamples = len(negativeSamplesFilenameList)\n",
    "\n",
    "    if numPositiveSamples > numNegativeSamples:\n",
    "        positiveSamplesFilenameList = positiveSamplesFilenameList[:numNegativeSamples]\n",
    "        numPositiveSamples = len(positiveSamplesFilenameList)\n",
    "    elif numNegativeSamples > numPositiveSamples:\n",
    "        negativeSamplesFilenameList = negativeSamplesFilenameList[:numPositiveSamples]\n",
    "        numNegativeSamples = len(negativeSamplesFilenameList)\n",
    "    assert(numPositiveSamples == numNegativeSamples)\n",
    "\n",
    "    numSamples = numPositiveSamples + numNegativeSamples\n",
    "\n",
    "    numTrainSamples = math.floor(numSamples*trainRatio)\n",
    "    numTestSamples = math.floor(numSamples*testRatio)\n",
    "    numValSamples = math.floor(numSamples*valRatio)\n",
    "\n",
    "\n",
    "    unsortedSamplesInfo = {'posDir':unsortedPositiveSamplesDir, 'negDir':unsortedNegativeSamplesDir, 'posFilenameList':positiveSamplesFilenameList,\n",
    "                           'negFilenameList':negativeSamplesFilenameList}\n",
    "\n",
    "    trainCopyInfo = {'num':numTrainSamples, 'posDir':trainPositiveDir, 'negDir':trainNegativeDir}\n",
    "    testCopyInfo = {'num':numTestSamples, 'posDir':testPositiveDir, 'negDir':testNegativeDir}\n",
    "    valCopyInfo = {'num':numValSamples, 'posDir':valPositiveDir, 'negDir':valNegativeDir}\n",
    "\n",
    "    def copyImagesInPartition(unsortedSamplesInfo:dict, partitionCopyInfo:dict):\n",
    "        for _ in range(math.floor(partitionCopyInfo['num']*positiveRatio)):\n",
    "            copyImage(unsortedSamplesInfo['posFilenameList'], unsortedSamplesInfo['posDir'], partitionCopyInfo['posDir'])\n",
    "        for _ in range(math.floor(partitionCopyInfo['num']*(1. - positiveRatio))):\n",
    "            copyImage(unsortedSamplesInfo['negFilenameList'], unsortedSamplesInfo['negDir'], partitionCopyInfo['negDir'])\n",
    "\n",
    "    def copyImage(sampleFilenameList, srcDir, dstDir):\n",
    "        filename = sampleFilenameList.pop()\n",
    "        src = os.path.join(srcDir, filename)\n",
    "        dst = os.path.join(dstDir, filename)\n",
    "        try:\n",
    "            shutil.copyfile(src, dst)\n",
    "        except PermissionError: # Ignores straggler files such as notebook checkpoints\n",
    "            pass\n",
    "\n",
    "    sampleDirectorySizes = [len(directory) for directory in [\n",
    "        os.listdir(trainPositiveDir), os.listdir(trainNegativeDir), os.listdir(testPositiveDir), os.listdir(testNegativeDir),\n",
    "        os.listdir(testPositiveDir), os.listdir(testNegativeDir)]]\n",
    "\n",
    "    if all(size == 0 for size in sampleDirectorySizes):\n",
    "        copyImagesInPartition(unsortedSamplesInfo, trainCopyInfo)\n",
    "        copyImagesInPartition(unsortedSamplesInfo, testCopyInfo)\n",
    "        copyImagesInPartition(unsortedSamplesInfo, valCopyInfo)\n",
    "    else:\n",
    "        raise Exception(\"Sorted image directories are not empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b820981-9e6d-452e-8c2a-87527c8a67b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "[*Optional*]: Test whether a sample handful of the images were copied to the correct folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbcc446d-f176-4b97-810a-cf7d7883aac3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "runImageCopyTest = False\n",
    "\n",
    "comparisonSampleSize = 50\n",
    "imageFiletype = 'png'\n",
    "##\n",
    "\n",
    "if runImageCopyTest and performCopy:\n",
    "    # These must be redefined here since they were popped\n",
    "    positiveSamplesFilenameList = os.listdir(unsortedPositiveSamplesDir)\n",
    "    negativeSamplesFilenameList = os.listdir(unsortedNegativeSamplesDir)\n",
    "\n",
    "    sortedTrainPositiveFilenameList = os.listdir(trainPositiveDir)\n",
    "    sortedTrainNegativeFilenameList = os.listdir(trainNegativeDir)\n",
    "    sortedTestPositiveFilenameList = os.listdir(testPositiveDir)\n",
    "    sortedTestNegativeFilenameList = os.listdir(testNegativeDir)\n",
    "    sortedValPositiveFilenameList = os.listdir(valPositiveDir)\n",
    "    sortedValNegativeFilenameList = os.listdir(valNegativeDir)\n",
    "    random.shuffle(sortedTrainPositiveFilenameList)\n",
    "    random.shuffle(sortedTrainNegativeFilenameList)\n",
    "    random.shuffle(sortedTestPositiveFilenameList)\n",
    "    random.shuffle(sortedTestNegativeFilenameList)\n",
    "    random.shuffle(sortedValPositiveFilenameList)\n",
    "    random.shuffle(sortedValNegativeFilenameList)\n",
    "\n",
    "    allPositiveFilenameLists = [sortedTrainPositiveFilenameList, sortedTestPositiveFilenameList, sortedValPositiveFilenameList]\n",
    "    allNegativeFilenameLists = [sortedTrainNegativeFilenameList, sortedTestNegativeFilenameList, sortedValNegativeFilenameList]\n",
    "\n",
    "    def matchesImageFiletype(sampleFilename : str, imageFiletype : str): # Needed to ignore straggler files such as notebook checkpoints\n",
    "        return sampleFilename[:len(imageFiletype)] == imageFiletype\n",
    "\n",
    "    for fList in allPositiveFilenameLists:\n",
    "        assert(all(sampleFilename in positiveSamplesFilenameList\n",
    "                   for sampleFilename in fList[:comparisonSampleSize]\n",
    "                   if matchesImageFiletype(sampleFilename, imageFiletype)))\n",
    "    for fList in allNegativeFilenameLists:\n",
    "        assert(all(sampleFilename in negativeSamplesFilenameList\n",
    "                   for sampleFilename in fList[:comparisonSampleSize]\n",
    "                   if matchesImageFiletype(sampleFilename, imageFiletype)))\n",
    "    print('Test was succesful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c43ac-71fa-40e3-b850-d0a924b2bd75",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3 Data generators\n",
    "\n",
    "The data generators themselves can rescale the input pixel values to the [0, 1] range and convert to grayscale. Note that the EfficientNet baseline model expects 3D pixel floats in the [0-255] range. Thus, a seperate set of data generators is made for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812df1dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1292 images belonging to 2 classes.\n",
      "Found 430 images belonging to 2 classes.\n",
      "Found 430 images belonging to 2 classes.\n",
      "Found 1292 images belonging to 2 classes.\n",
      "Found 430 images belonging to 2 classes.\n",
      "Found 430 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ncapsNetInputShape = (36, 36) # MULTIMNIST dimensions\\n\\ncapsNetTrainDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\\ncapsNetTestDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\\ncapsNetValDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\\n\\ncapsNetTrainDataGenerator = capsNetTrainDataGeneratorFactory.flow_from_directory( # Batch generator\\n    trainDir,\\n    target_size = capsNetInputShape,\\n    batch_size = batchSize,\\n    color_mode = 'grayscale',\\n    class_mode = 'binary')\\ncapsNetTestDataGenerator = capsNetTestDataGeneratorFactory.flow_from_directory(\\n    testDir,\\n    target_size = capsNetInputShape,\\n    batch_size = batchSize,\\n    color_mode = 'grayscale',\\n    class_mode = 'binary')\\ncapsNetValDataGenerator = capsNetValDataGeneratorFactory.flow_from_directory(\\n    valDir,\\n    target_size = capsNetInputShape,\\n    batch_size = batchSize,\\n    color_mode = 'grayscale',\\n    class_mode = 'binary')\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "batchSize = 75\n",
    "imageResolution = (150, 150) # Can be tweaked! But TESTME: This might require rescaling of some network dimensions\n",
    "##\n",
    "\n",
    "trainDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "testDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "valDataGenerator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "trainDataGenerator = trainDataGeneratorFactory.flow_from_directory( # Batch generator\n",
    "    trainDir,\n",
    "    target_size = imageResolution,\n",
    "    batch_size = batchSize,\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'binary')\n",
    "testDataGenerator = testDataGeneratorFactory.flow_from_directory(\n",
    "    testDir,\n",
    "    target_size = imageResolution,\n",
    "    batch_size = batchSize,\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'binary')\n",
    "valDataGenerator = testDataGeneratorFactory.flow_from_directory(\n",
    "    valDir,\n",
    "    target_size = imageResolution,\n",
    "    batch_size = batchSize,\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'binary')\n",
    "\n",
    "\n",
    "efficientNetTrainDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator()\n",
    "efficientNetTestDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator()\n",
    "efficientNetValDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "efficientNetTrainDataGenerator = efficientNetTrainDataGeneratorFactory.flow_from_directory( # Batch generator\n",
    "    trainDir,\n",
    "    target_size = imageResolution,\n",
    "    batch_size = batchSize,\n",
    "    class_mode = 'binary')\n",
    "efficientNetTestDataGenerator = efficientNetTestDataGeneratorFactory.flow_from_directory(\n",
    "    testDir,\n",
    "    target_size = imageResolution,\n",
    "    batch_size = batchSize,\n",
    "    class_mode = 'binary')\n",
    "efficientNetValDataGenerator = efficientNetValDataGeneratorFactory.flow_from_directory(\n",
    "    valDir,\n",
    "    target_size = imageResolution,\n",
    "    batch_size = batchSize,\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16640509-5c84-4ce2-875b-efc0b1282497",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 Baseline models implementation\n",
    "A series of baseline models are implemented for comparative study.\n",
    "- A simple vanilla CNN model with a standard architecture\n",
    "- Pretrained EfficientNet as feature extraction\n",
    "- Finetuned pretrained EfficientNet\n",
    "- EfficientNet manually trained on MNIST\n",
    "\n",
    "Note that compiling the finetuned EfficientNet enforces compiling the feature extractor, since training the top classifier on this is a part of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ee021-52da-4641-aaea-1b6a68bb78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "compileBaselineCNN = False\n",
    "compileEfficientNetFE = False\n",
    "compileFinetunedEfficientNet = False\n",
    "compileMNISTEfficientNet = True\n",
    "##\n",
    "\n",
    "if compileFinetunedEfficientNet:\n",
    "    compileEfficientNetBE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd55f65-87cf-4943-937b-dfa2aa61f78d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.1 Building baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a32fada-b2a5-4f7e-b39f-670a1de4c969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baselineCNN = models.Sequential(name='BaselineCNN')\n",
    "baselineCNN.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(*imageResolution, 1)))\n",
    "baselineCNN.add(layers.MaxPooling2D((2,2)))\n",
    "baselineCNN.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "baselineCNN.add(layers.MaxPooling2D((2,2)))\n",
    "baselineCNN.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "baselineCNN.add(layers.MaxPooling2D((2,2)))\n",
    "baselineCNN.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "baselineCNN.add(layers.MaxPooling2D((2,2)))\n",
    "baselineCNN.add(layers.Flatten())\n",
    "baselineCNN.add(layers.Dropout(0.5))\n",
    "baselineCNN.add(layers.Dense(512, activation='relu'))\n",
    "baselineCNN.add(layers.Dense(1, activation='sigmoid'))\n",
    "#baselineCNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9c6cc-38d9-4389-bd9a-a6d66f6d94b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.2 EfficientNet bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a878253-c77a-43a5-802a-b7237f60d526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "efficientNetMinInputShape = (32, 32, 1)\n",
    "# MNISTInputShape = (28, 28, 1)\n",
    "\n",
    "# Pretrained EfficientNet\n",
    "efficientNetB0Base = keras.applications.efficientnet.EfficientNetB0(\n",
    "    include_top = False,\n",
    "    input_shape = (*imageResolution, 3),\n",
    "    # Try with pooling='avg'/'max'?\n",
    "    weights = 'imagenet')\n",
    "efficientNetB0Base.trainable = False\n",
    "\n",
    "# For MNIST\n",
    "untrainedEfficientNetB0Base = keras.applications.efficientnet.EfficientNetB0(\n",
    "    include_top = False,\n",
    "    input_shape = efficientNetMinInputShape,\n",
    "    weights = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba38173-ca9c-461e-a9fa-db1963ffa9fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.3 Classifier for pretrained EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f766332e-7b92-46d0-95f4-36043fa7c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetBaseCanonicalOutputShape = (5, 5, 1280)\n",
    "efficientNetBaseCanonicalFlatOutputSize = np.product(efficientNetBaseCanonicalOutputShape)\n",
    "efficientNetBaseCanonicalFlatOutputSizeGrayscale = 1280 # Wait, this is the channel axis, right? Maybe EfficientNet was a bad choice...\n",
    "\n",
    "efficientNetB0FEClassifier = models.Sequential(name='efficientNetB0FEClassifier')\n",
    "efficientNetB0FEClassifier.add(layers.Dense(1024, activation='relu', input_dim=efficientNetBaseCanonicalFlatOutputSize))\n",
    "efficientNetB0FEClassifier.add(layers.Dense(256, activation='relu')) \n",
    "efficientNetB0FEClassifier.add(layers.Dropout(0.5))\n",
    "efficientNetB0FEClassifier.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15772b45-7265-4df4-ac9a-1ded2f3f737f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### 2.1.4 Classifiers for MNIST EfficientNet\n",
    "Two classifiers are built. The \"categorical classifier\", for training on MNIST, with output length of 10, and the \"binary classifier\", for training and use on our binary dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e8e456d-601f-4337-bdc8-a532deada23e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "efficientNetB0MNISTCategoricalClassifier = models.Sequential(name='efficientNetB0MNISTCategoricalClassifier')\n",
    "efficientNetB0MNISTCategoricalClassifier.add(layers.Dense(1024, activation='relu', input_dim=efficientNetBaseCanonicalFlatOutputSizeGrayscale)) # New\n",
    "efficientNetB0MNISTCategoricalClassifier.add(layers.Dense(256, activation='relu')) \n",
    "efficientNetB0MNISTCategoricalClassifier.add(layers.Dropout(0.5))\n",
    "efficientNetB0MNISTCategoricalClassifier.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "efficientNetB0MNISTBinaryClassifier = models.Sequential(name='efficientNetB0MNISTBinaryClassifier')\n",
    "efficientNetB0MNISTBinaryClassifier.add(layers.Dense(1024, activation='relu', input_dim=efficientNetBaseCanonicalFlatOutputSizeGrayscale)) # New\n",
    "efficientNetB0MNISTBinaryClassifier.add(layers.Dense(256, activation='relu')) \n",
    "efficientNetB0MNISTBinaryClassifier.add(layers.Dropout(0.5))\n",
    "efficientNetB0MNISTBinaryClassifier.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9047a29d-b122-44ec-b826-59f68d205622",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.1 Feature extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91db39f8-cf59-4120-b15c-b9b4574f577c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extractFeatures(model, generator, modelOutputShape:tuple, numSamples=None):\n",
    "    if not numSamples:\n",
    "        numSamples = generator.n\n",
    "    if numSamples % batchSize != 0:\n",
    "        numSamples -= (numSamples % batchSize)\n",
    "    features = np.zeros(shape=(numSamples, *modelOutputShape))\n",
    "    labels = np.zeros(shape=(numSamples))\n",
    "    i = 0\n",
    "    for inputBatch, labelBatch in generator:\n",
    "        featureBatch = model.predict(inputBatch)\n",
    "        features[i*batchSize : (i + 1)*batchSize] = featureBatch\n",
    "        labels[i*batchSize : (i + 1)*batchSize] = labelBatch\n",
    "        i += 1\n",
    "        if i*batchSize >= numSamples:\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666a057-ace4-4ef7-8cf9-19ee08c7f8d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.2 Pretrained EfficientNet feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5417e646-9746-466e-93a9-c4a8842d08f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if compileEfficientNetFE:\n",
    "    efficientNetTrainFeatures, efficientNetTrainLabels = extractFeatures(efficientNetB0Base, efficientNetTrainDataGenerator, efficientNetBaseCanonicalOutputShape)\n",
    "    efficientNetTestFeatures, efficientNetTestLabels = extractFeatures(efficientNetB0Base, efficientNetTestDataGenerator, efficientNetBaseCanonicalOutputShape)\n",
    "    efficientNetValFeatures, efficientNetValLabels = extractFeatures(efficientNetB0Base, efficientNetValDataGenerator, efficientNetBaseCanonicalOutputShape)\n",
    "\n",
    "    efficientNetTrainFeatures = np.reshape(efficientNetTrainFeatures, (efficientNetTrainFeatures.shape[0], efficientNetBaseCanonicalFlatOutputSize))\n",
    "    efficientNetTestFeatures = np.reshape(efficientNetTestFeatures, (efficientNetTestFeatures.shape[0], efficientNetBaseCanonicalFlatOutputSize))\n",
    "    efficientNetValFeatures = np.reshape(efficientNetValFeatures, (efficientNetValFeatures.shape[0], efficientNetBaseCanonicalFlatOutputSize))\n",
    "\n",
    "    flattenedEfficientNetFeatureShape = efficientNetTrainFeatures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca227002-d7aa-4a13-87a4-6ed112acbcdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3 Compilation of baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "231208b1-3842-4504-be75-9c85b7c3fc64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "metrics = [keras.metrics.BinaryAccuracy(), keras.metrics.BinaryCrossentropy(), keras.metrics.AUC(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "metricNames = ['binary accuracy', 'binary cross entropy', 'AUC', 'precision', 'recall']\n",
    "\n",
    "epochs = 100\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71600fa3-3018-44bd-b6a7-396ed206ecc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.3.1 Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a11b13db-7a02-4fb7-a46e-93de70891aaa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compileBaselineCNN:\n",
    "    baselineCNN.compile(optimizer=tfa.optimizers.Yogi(),\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=metrics)\n",
    "    baselineCNNHistory = baselineCNN.fit(trainDataGenerator,\n",
    "                                        epochs=epochs,\n",
    "                                        validation_data=valDataGenerator)\n",
    "    baselineCNN.save('baselineCNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd508e-6e75-488d-9951-166dc493a27a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.3.2 EfficientNet feature extraction classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcb5ce0c-b0d1-409a-a350-aba222b316ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compileEfficientNetFE or compileFinetunedEfficientNet:\n",
    "    efficientNetB0FEClassifier.compile(optimizer=tfa.optimizers.Yogi(),\n",
    "                                       loss='binary_crossentropy',\n",
    "                                       metrics=metrics)\n",
    "    efficientNetB0FEClassifierHistory = efficientNetB0FEClassifier.fit(efficientNetTrainFeatures, efficientNetTrainLabels,\n",
    "                                                                       epochs=epochs,\n",
    "                                                                       batch_size=batchSize,\n",
    "                                                                       validation_data=(efficientNetValFeatures, efficientNetValLabels))\n",
    "    efficientNetB0FEClassifier.save('efficientNetB0FEClassifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033508ff-d2e1-40a6-973b-9a74268165a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3.3 Finetuned EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89a8b7b6-a9c7-499e-84fc-1590ae95681a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Should we train this one less?\n",
    "##\n",
    "finetuningLearningRate = 1e-5\n",
    "layersToUnfreeze = ['top_conv', 'block7a_project_conv', 'block7a_dwconv']\n",
    "##\n",
    "\n",
    "if compileFinetunedEfficientNet:\n",
    "    trainableEfficientNetB0Base = efficientNetB0Base\n",
    "    trainableEfficientNetB0Base.trainable = True\n",
    "    for layer in trainableEfficientNetB0Base.layers:\n",
    "        if layer.name not in layersToUnfreeze:\n",
    "            layer.trainable = False\n",
    "\n",
    "    finetunedEfficientNetB0 = models.Sequential(name='finetunedEfficientNetB0')\n",
    "    finetunedEfficientNetB0.add(trainableEfficientNetB0Base)\n",
    "    finetunedEfficientNetB0.add(layers.Flatten())\n",
    "    finetunedEfficientNetB0.add(efficientNetB0FEClassifier) # Note that this is already trained\n",
    "    #finetunedEfficientNetB0.summary()\n",
    "\n",
    "    finetunedEfficientNetB0.compile(optimizer=tfa.optimizers.Yogi(lr=finetuningLearningRate),\n",
    "                                    loss='binary_crossentropy',\n",
    "                                    metrics=metrics)\n",
    "    finetunedEfficientNetB0History = finetunedEfficientNetB0.fit(efficientNetTrainDataGenerator,\n",
    "                                                                 epochs=epochs,\n",
    "                                                                 batch_size=batchSize,\n",
    "                                                                 validation_data=efficientNetValDataGenerator)\n",
    "    finetunedEfficientNetB0.save('finetunedEfficientNetB0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8b7da-f077-4450-b7ca-8852c604b91f",
   "metadata": {},
   "source": [
    "### 2.3.4 MNIST EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e014c7ac-c072-4b26-a799-4d31c8447f04",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MNISTEfficientNetB0Categorical\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, 1, 1, 1280)        4048991   \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1280)              0         \n",
      "=================================================================\n",
      "Total params: 4,048,991\n",
      "Trainable params: 4,006,972\n",
      "Non-trainable params: 42,019\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 237s 260ms/step - loss: 0.1527 - binary_accuracy: 0.9924 - binary_crossentropy: 0.6532 - auc_1: 0.9964 - precision_1: 0.9697 - recall_1: 0.9534\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 203s 254ms/step - loss: 0.1813 - binary_accuracy: 0.9912 - binary_crossentropy: 0.5001 - auc_1: 0.9953 - precision_1: 0.9666 - recall_1: 0.9442\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 203s 254ms/step - loss: 0.1058 - binary_accuracy: 0.9949 - binary_crossentropy: 0.4932 - auc_1: 0.9975 - precision_1: 0.9800 - recall_1: 0.9684\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 211s 263ms/step - loss: 0.0765 - binary_accuracy: 0.9962 - binary_crossentropy: 0.4818 - auc_1: 0.9983 - precision_1: 0.9851 - recall_1: 0.9767\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 210s 262ms/step - loss: 0.0598 - binary_accuracy: 0.9970 - binary_crossentropy: 0.5369 - auc_1: 0.9987 - precision_1: 0.9879 - recall_1: 0.9819\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 211s 264ms/step - loss: 0.0498 - binary_accuracy: 0.9974 - binary_crossentropy: 0.5194 - auc_1: 0.9990 - precision_1: 0.9897 - recall_1: 0.9846\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 210s 263ms/step - loss: 0.0458 - binary_accuracy: 0.9976 - binary_crossentropy: 0.5296 - auc_1: 0.9991 - precision_1: 0.9905 - recall_1: 0.9856\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 212s 264ms/step - loss: 0.0583 - binary_accuracy: 0.9972 - binary_crossentropy: 0.5099 - auc_1: 0.9987 - precision_1: 0.9890 - recall_1: 0.9831\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 211s 264ms/step - loss: 0.0423 - binary_accuracy: 0.9978 - binary_crossentropy: 0.4052 - auc_1: 0.9991 - precision_1: 0.9910 - recall_1: 0.9869\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 211s 264ms/step - loss: 0.0323 - binary_accuracy: 0.9983 - binary_crossentropy: 0.4639 - auc_1: 0.9994 - precision_1: 0.9933 - recall_1: 0.9899\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 210s 263ms/step - loss: 0.0317 - binary_accuracy: 0.9984 - binary_crossentropy: 0.4693 - auc_1: 0.9994 - precision_1: 0.9935 - recall_1: 0.9904\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 211s 264ms/step - loss: 0.0289 - binary_accuracy: 0.9984 - binary_crossentropy: 0.4509 - auc_1: 0.9994 - precision_1: 0.9935 - recall_1: 0.9909\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 212s 265ms/step - loss: 0.0255 - binary_accuracy: 0.9986 - binary_crossentropy: 0.4600 - auc_1: 0.9995 - precision_1: 0.9943 - recall_1: 0.9919\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 210s 262ms/step - loss: 0.0653 - binary_accuracy: 0.9967 - binary_crossentropy: 0.4761 - auc_1: 0.9987 - precision_1: 0.9876 - recall_1: 0.9793\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 211s 264ms/step - loss: 0.0412 - binary_accuracy: 0.9979 - binary_crossentropy: 0.4738 - auc_1: 0.9992 - precision_1: 0.9915 - recall_1: 0.9872\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 210s 262ms/step - loss: 0.0384 - binary_accuracy: 0.9980 - binary_crossentropy: 0.4988 - auc_1: 0.9993 - precision_1: 0.9918 - recall_1: 0.9883\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 212s 265ms/step - loss: 0.0271 - binary_accuracy: 0.9985 - binary_crossentropy: 0.5722 - auc_1: 0.9995 - precision_1: 0.9940 - recall_1: 0.9915\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 211s 264ms/step - loss: 0.0219 - binary_accuracy: 0.9989 - binary_crossentropy: 0.5514 - auc_1: 0.9996 - precision_1: 0.9951 - recall_1: 0.9934\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 212s 264ms/step - loss: 0.0710 - binary_accuracy: 0.9965 - binary_crossentropy: 0.5509 - auc_1: 0.9986 - precision_1: 0.9866 - recall_1: 0.9781\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 210s 263ms/step - loss: 0.0733 - binary_accuracy: 0.9963 - binary_crossentropy: 0.5463 - auc_1: 0.9985 - precision_1: 0.9854 - recall_1: 0.9776\n",
      "Epoch 21/100\n",
      "615/800 [======================>.......] - ETA: 48s - loss: 0.0357 - binary_accuracy: 0.9981 - binary_crossentropy: 0.5763 - auc_1: 0.9992 - precision_1: 0.9921 - recall_1: 0.9887"
     ]
    }
   ],
   "source": [
    "##\n",
    "MNISTTrainEpochs = 100\n",
    "##\n",
    "\n",
    "if compileMNISTEfficientNet:\n",
    "    MNISTEfficientNetB0Categorical = models.Sequential(name='MNISTEfficientNetB0Categorical')\n",
    "    MNISTEfficientNetB0Categorical.add(untrainedEfficientNetB0Base)\n",
    "    MNISTEfficientNetB0Categorical.add(layers.Flatten())\n",
    "    MNISTEfficientNetB0Categorical.summary()\n",
    "    MNISTEfficientNetB0Categorical.add(efficientNetB0MNISTCategoricalClassifier)\n",
    "    \n",
    "    (MNISTTrainImages, MNISTTrainLabels), (MNISTTestImages, MNISTTestLabels) = mnist.load_data()\n",
    "    \n",
    "    MNISTTrainImages = MNISTTrainImages.astype('float32') / 255\n",
    "    MNISTTestImages = MNISTTestImages.astype('float32') / 255\n",
    "    \n",
    "    # Transform to conform to minimum input size by padding with 4 white pixels on each spatial axis (2 before and after)\n",
    "    MNISTTrainImages = np.pad(MNISTTrainImages, pad_width=((0, 0), (2, 2), (2,2)), constant_values=(1., 1.))\n",
    "    MNISTTestImages = np.pad(MNISTTestImages, pad_width=((0,0), (2,2), (2,2)), constant_values=(1., 1.))\n",
    "    \n",
    "    MNISTTrainLabels = keras.utils.to_categorical(MNISTTrainLabels)\n",
    "    MNISTTestLabels = keras.utils.to_categorical(MNISTTestLabels)\n",
    "    \n",
    "    MNISTEfficientNetB0Categorical.compile(optimizer=tfa.optimizers.Yogi(),\n",
    "                               loss='categorical_crossentropy',\n",
    "                               metrics=metrics) # Could cut the metrics out\n",
    "    \n",
    "    MNISTEfficientNetB0Categorical.fit(MNISTTrainImages, MNISTTrainLabels, epochs=MNISTTrainEpochs, batch_size=batchSize)\n",
    "    MNISTEfficientNetB0.save('MNISTEfficientNetB0Categorical.h5')\n",
    "    \n",
    "    \n",
    "    MNISTEfficientNetB0Binary = models.Sequential(name='MNISTEfficientNetB0Binary')\n",
    "\n",
    "    # Architecture for downsampling from (150, 150, 3) to (38, 38, 1)\n",
    "    MNISTEfficientNetB0Binary.add(layers.MaxPool2D(pool_size=(3, 3), strides=3, padding='same', input_dim=(*imageResolution, 3))) # Output shape = (50, 50, 3)?\n",
    "    MNISTEfficientNetB0Binary.add(layers.Conv2D(1, 5, padding='same', activation = 'relu')) # Output shape = (42, 42, 3)?\n",
    "    MNISTEfficientNetB0Binary.add(layers.Conv2D(1, 3, padding='same', activation = 'relu')) # Output shape = (38, 38, 3)?\n",
    "    MNISTEfficientNetB0Binary.add(layers.GlobalMaxPool1D()) # Output shape = (38, 38, 1)?\n",
    "    #\n",
    "                                  \n",
    "    trainedEfficientNetB0Base = untrainedEfficientNetB0Base\n",
    "    trainedEfficientNetB0Base.trainable = False\n",
    "    \n",
    "    MNISTEfficientNetB0Binary.add(trainedEfficientNetB0Base)\n",
    "    MNISTEfficientNetB0Binary.add(layers.Flatten())\n",
    "    MNISTEfficientNetB0Binary.add(efficientNetB0MNISTBinaryClassifier)\n",
    "    #MNISTEfficientNetB0Binary.summary()\n",
    "    \n",
    "    MNISTEfficientNetB0Binary.compile(optimizer=tfa.optimizers.Yogi(),\n",
    "                                       loss='binary_crossentropy',\n",
    "                                       metrics=metrics)\n",
    "    MNISTEfficientNetB0BinaryClassifierTrainingHistory = MNISTEfficientNetB0Binary.fit(efficientNetTrainFeatures, efficientNetTrainLabels,\n",
    "                                                                       epochs=epochs,\n",
    "                                                                       batch_size=batchSize,\n",
    "                                                                       validation_data=(efficientNetValFeatures, efficientNetValLabels))\n",
    "    \n",
    "    trainedEfficientNetB0Base.trainable = true\n",
    "    MNISTEfficientNetB0Binary.compile(optimizer=tfa.optimizers.Yogi(lr=finetuningLearningRate),\n",
    "                                       loss='binary_crossentropy',\n",
    "                                       metrics=metrics)\n",
    "    MNISTEfficientNetB0BinaryClassifierTrainingHistory = MNISTEfficientNetB0Binary.fit(efficientNetTrainFeatures, efficientNetTrainLabels,\n",
    "                                                                       epochs=epochs,\n",
    "                                                                       batch_size=batchSize,\n",
    "                                                                       validation_data=(efficientNetValFeatures, efficientNetValLabels))\n",
    "    MNISTEfficientNetB0Binary.save('MNISTEfficientNetB0Binary.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6850c60-42dc-4512-b809-cd623d2568e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.4.1 History plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae21dfa6-4d49-4f2f-b6e1-0ec27fd24667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipMetricsKeysWithNames(keys, metricNames):\n",
    "    metricKeys = list(keys)\n",
    "    metricKeysTrainingOnly = metricKeys[1:len(metricKeys) // 2] # Ignores the generic loss metric and truncates all validation histories\n",
    "    assert(len(metricNames) == len(metricKeysTrainingOnly))\n",
    "    zippedMetrics = zip(metricKeysTrainingOnly, metricNames)\n",
    "    return zippedMetrics\n",
    "\n",
    "def plotTrainingHistories(history, metricsKeysNamesZip, modelName:str):\n",
    "    for (key, name) in metricsKeysNamesZip:\n",
    "        metricHistory = history.history[key]\n",
    "        metricValHistory = history.history[f'val_{key}']\n",
    "        plotOneTrainingHistory(metricHistory, metricValHistory, name, modelName)\n",
    "\n",
    "def plotOneTrainingHistory(metricHistory, metricValHistory, metricName, modelName):\n",
    "    plt.figure()\n",
    "    epochs = range(1, len(metricHistory) + 1)\n",
    "    plt.plot(epochs, metricHistory, 'bo', label=f'Training {metricName}')\n",
    "    plt.plot(epochs, metricValHistory, 'r', label=f'Validation {metricName}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metricName)\n",
    "    plt.title(f'Training and validation {metricName} for {modelName}')\n",
    "    plt.legend()\n",
    "    shortModelName = shortenModelOrMetricName(modelName)\n",
    "    shortMetricName = shortenModelOrMetricName(metricName)\n",
    "    plt.savefig(f'{shortModelName}{shortMetricName}.jpeg', transparent=False, bbox_inches='tight')\n",
    "\n",
    "def shortenModelOrMetricName(modelOrMetricName:str):\n",
    "    return modelOrMetricName.title().replace(' ','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08dc55c-4866-445f-bc32-737f92f66342",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.5.1 History plots for baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d99f9-684e-4933-a721-eb8aa475c651",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compileBaselineCNN:\n",
    "    metricsKeysNames = zipMetricsKeysWithNames(baselineCNNHistory.history.keys(), metricNames)\n",
    "    plotTrainingHistories(baselineCNNHistory, metricsKeysNames, 'Baseline CNN')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085c309d-a017-46e7-8807-0b0d81eeb74c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### 2.5.2 History plots for EfficientNet feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03930a61-eb43-4eb6-9d73-99a359daeee4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compileEfficientNetFE:\n",
    "    metricsKeysNames = zipMetricsKeysWithNames(efficientNetB0FEClassifierHistory.history.keys(), metricNames)\n",
    "    plotTrainingHistories(efficientNetB0FEClassifierHistory, metricsKeysNames, 'EfficientNet feature extraction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc230ec-898c-4772-87ad-4bda3f11a486",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### 2.5.3 History plots for finetuned EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967da63-837e-4dc4-8652-c3ec6f6c6a01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compileFinetunedEfficientNet:\n",
    "    metricsKeysNames = zipMetricsKeysWithNames(finetunedEfficientNetB0History.history.keys(), metricNames)\n",
    "    plotTrainingHistories(finetunedEfficientNetB0History, metricsKeysNames, 'Finetuned EfficientNet')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9145f7-f55b-45c8-b12d-dc8d3545894d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### 2.5.4 MNIST-EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d60c73-396a-4b51-9c31-cc1c24966546",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compileMNISTEfficientNet:\n",
    "    metricsKeysNames = zipMetricsKeysWithNames(MNISTEfficientNetB0Binary.history.keys(), metricNames)\n",
    "    plotTrainingHistories(MNISTEfficientNetB0BinaryHistory, metricsKeysNames, 'MNIST EfficientNet')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429fbef3-8474-40d7-8315-7ba42df514f8",
   "metadata": {},
   "source": [
    "### 2.5.5 Function for generating aggregate multiplots from saved plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddba04-fb36-4691-b647-7f5c3c628153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "shortModelNames = ['BaselineCnn', 'EfficientNetFeatureExtraction', 'FinetunedEfficientNet', 'MNISTEfficientNet']\n",
    "shortMetricNames = ['BinaryAccuracy', 'BinaryCrossEntropy', 'Precision', 'Recall']\n",
    "\n",
    "generateMultiplot = True\n",
    "#\n",
    "\n",
    "def plotAggregateStats(shortModelNames, shortMetricNames):\n",
    "    numModels = len(shortModelNames)\n",
    "    numMetrics = len(shortMetricNames)\n",
    "\n",
    "    subplotIndex = 1\n",
    "    for model in shortModelNames:\n",
    "        for metric in shortMetricNames:\n",
    "            plt.subplot(numModels, numMetrics, subplotIndex)\n",
    "            graph = plt.imread(f'{model}{metric}.png') # Change to jpeg!\n",
    "            plt.imshow(graph) # Does this work?\n",
    "            subplotIndex += 1\n",
    "    plt.suptitle('Training statistics for baseline models', y=1.05)\n",
    "    plt.savefig(f'AggregateTrainStats{numModels}Models{numMetrics}Metrics.jpeg')\n",
    "    \n",
    "if generateMultiplot:\n",
    "    plotAggregateStats(shortModelNames, shortMetricNames)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dataScience] *",
   "language": "python",
   "name": "conda-env-dataScience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
