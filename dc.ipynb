{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65c1f28",
   "metadata": {},
   "source": [
    "# Binary classification of commutative diagrams\n",
    "## 1. Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b087f593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import torch\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "#import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa # Needed for Yogi optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbf2aa",
   "metadata": {},
   "source": [
    "### 1.1 Expand working directory with folders for training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551ef7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "unsortedSamplesDirName = 'png-2021-all_contexts'\n",
    "##\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "unsortedSamplesDir = os.path.join(cwd, unsortedSamplesDirName)\n",
    "assert('positive' in os.listdir(unsortedSamplesDir) and 'negative' in os.listdir(unsortedSamplesDir))\n",
    "unsortedPositiveSamplesDir = os.path.join(unsortedSamplesDir, 'positive')\n",
    "unsortedNegativeSamplesDir = os.path.join(unsortedSamplesDir, 'negative')\n",
    "\n",
    "sortedSamplesDir = os.path.join(cwd, 'sortedSamples')\n",
    "os.makedirs(sortedSamplesDir, exist_ok=True)\n",
    "\n",
    "trainDir = os.path.join(sortedSamplesDir, 'train')\n",
    "testDir = os.path.join(sortedSamplesDir, 'test')\n",
    "valDir = os.path.join(sortedSamplesDir, 'val')\n",
    "os.makedirs(trainDir, exist_ok=True)\n",
    "os.makedirs(testDir, exist_ok=True)\n",
    "os.makedirs(valDir, exist_ok=True)\n",
    "\n",
    "trainPositiveDir = os.path.join(trainDir, 'positive')\n",
    "trainNegativeDir = os.path.join(trainDir, 'negative')\n",
    "testPositiveDir = os.path.join(testDir, 'positive')\n",
    "testNegativeDir = os.path.join(testDir, 'negative')\n",
    "valPositiveDir = os.path.join(valDir, 'positive')\n",
    "valNegativeDir = os.path.join(valDir, 'negative')\n",
    "os.makedirs(trainPositiveDir, exist_ok=True)\n",
    "os.makedirs(trainNegativeDir, exist_ok=True)\n",
    "os.makedirs(testPositiveDir, exist_ok=True)\n",
    "os.makedirs(testNegativeDir, exist_ok=True)\n",
    "os.makedirs(valPositiveDir, exist_ok=True)\n",
    "os.makedirs(valNegativeDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3344b2e-0d63-41d6-aafa-eac29f9b7005",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 Copy images into train, test and validation folders\n",
    "The code currently randomly truncates the greater partition between positive and negative to achieve parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8afd1c9-8b49-43ba-83b9-e9c9588b7788",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Sorted image directories are not empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 59>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m     copyImagesInPartition(unsortedSamplesInfo, valCopyInfo)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorted image directories are not empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# TRASH: Is this actually more readable than the functions above?\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03mif all(size == 0 for size in sampleDirectorySizes):\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    for _ in range(math.floor(numTrainSamples*positiveRatio)):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03melse:\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    raise Exception(\"Sorted image directories are not empty.\")\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mException\u001b[0m: Sorted image directories are not empty."
     ]
    }
   ],
   "source": [
    "##\n",
    "trainRatio = 0.6\n",
    "testRatio = 0.2\n",
    "valRatio = 0.2\n",
    "assert(trainRatio + testRatio + valRatio == 1.)\n",
    "\n",
    "positiveRatio = 0.5 # Desired ratio of positive samples in the sorted data\n",
    "##\n",
    "\n",
    "\n",
    "positiveSamplesFilenameList = os.listdir(unsortedPositiveSamplesDir)\n",
    "negativeSamplesFilenameList = os.listdir(unsortedNegativeSamplesDir)\n",
    "random.shuffle(positiveSamplesFilenameList)\n",
    "random.shuffle(negativeSamplesFilenameList)\n",
    "numPositiveSamples = len(positiveSamplesFilenameList)\n",
    "numNegativeSamples = len(negativeSamplesFilenameList)\n",
    "\n",
    "if numPositiveSamples > numNegativeSamples:\n",
    "    positiveSamplesFilenameList = positiveSamplesFilenameList[:numNegativeSamples]\n",
    "    numPositiveSamples = len(positiveSamplesFilenameList)\n",
    "elif numNegativeSamples > numPositiveSamples:\n",
    "    negativeSamplesFilenameList = negativeSamplesFilenameList[:numPositiveSamples]\n",
    "    numNegativeSamples = len(negativeSamplesFilenameList)\n",
    "assert(numPositiveSamples == numNegativeSamples)\n",
    "    \n",
    "numSamples = numPositiveSamples + numNegativeSamples\n",
    "\n",
    "numTrainSamples = math.floor(numSamples*trainRatio)\n",
    "numTestSamples = math.floor(numSamples*testRatio)\n",
    "numValSamples = math.floor(numSamples*valRatio)\n",
    "\n",
    "\n",
    "unsortedSamplesInfo = {'posDir':unsortedPositiveSamplesDir, 'negDir':unsortedNegativeSamplesDir, 'posFilenameList':positiveSamplesFilenameList,\n",
    "                       'negFilenameList':negativeSamplesFilenameList}\n",
    "\n",
    "trainCopyInfo = {'num':numTrainSamples, 'posDir':trainPositiveDir, 'negDir':trainNegativeDir}\n",
    "testCopyInfo = {'num':numTestSamples, 'posDir':testPositiveDir, 'negDir':testNegativeDir}\n",
    "valCopyInfo = {'num':numValSamples, 'posDir':valPositiveDir, 'negDir':valNegativeDir}\n",
    "\n",
    "def copyImagesInPartition(unsortedSamplesInfo:dict, partitionCopyInfo:dict):\n",
    "    for _ in range(math.floor(partitionCopyInfo['num']*positiveRatio)):\n",
    "        copyImage(unsortedSamplesInfo['posFilenameList'], unsortedSamplesInfo['posDir'], partitionCopyInfo['posDir'])\n",
    "    for _ in range(math.floor(partitionCopyInfo['num']*(1. - positiveRatio))):\n",
    "        copyImage(unsortedSamplesInfo['negFilenameList'], unsortedSamplesInfo['negDir'], partitionCopyInfo['negDir'])\n",
    "\n",
    "def copyImage(sampleFilenameList, srcDir, dstDir):\n",
    "    filename = sampleFilenameList.pop()\n",
    "    src = os.path.join(srcDir, filename)\n",
    "    dst = os.path.join(dstDir, filename)\n",
    "    try:\n",
    "        shutil.copyfile(src, dst)\n",
    "    except PermissionError: # Ignores straggler files such as notebook checkpoints\n",
    "        pass\n",
    "\n",
    "sampleDirectorySizes = [len(directory) for directory in [\n",
    "    os.listdir(trainPositiveDir), os.listdir(trainNegativeDir), os.listdir(testPositiveDir), os.listdir(testNegativeDir),\n",
    "    os.listdir(testPositiveDir), os.listdir(testNegativeDir)]]\n",
    "\n",
    "if all(size == 0 for size in sampleDirectorySizes):\n",
    "    copyImagesInPartition(unsortedSamplesInfo, trainCopyInfo)\n",
    "    copyImagesInPartition(unsortedSamplesInfo, testCopyInfo)\n",
    "    copyImagesInPartition(unsortedSamplesInfo, valCopyInfo)\n",
    "else:\n",
    "    raise Exception(\"Sorted image directories are not empty.\")\n",
    "\n",
    "# TRASH: Is this actually more readable than the functions above?\n",
    "\"\"\"\n",
    "if all(size == 0 for size in sampleDirectorySizes):\n",
    "    for _ in range(math.floor(numTrainSamples*positiveRatio)):\n",
    "        filename = positiveSamplesFilenameList.pop()\n",
    "        src = os.path.join(unsortedPositiveSamplesDir, filename)\n",
    "        dst = os.path.join(trainPositiveDir, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for _ in range(math.floor(numTrainSamples*(1. - positiveRatio))):\n",
    "        filename = negativeSamplesFilenameList.pop()\n",
    "        src = os.path.join(unsortedNegativeSamplesDir, filename)\n",
    "        dst = os.path.join(trainNegativeDir, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for _ in range(math.floor(numTestSamples*positiveRatio)):\n",
    "        filename = positiveSamplesFilenameList.pop()\n",
    "        src = os.path.join(unsortedPositiveSamplesDir, filename)\n",
    "        dst = os.path.join(testPositiveDir, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for _ in range(math.floor(numTestSamples*(1. - positiveRatio))):\n",
    "        filename = negativeSamplesFilenameList.pop()\n",
    "        src = os.path.join(unsortedNegativeSamplesDir, filename)\n",
    "        dst = os.path.join(testNegativeDir, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for _ in range(math.floor(numValSamples*positiveRatio)):\n",
    "        filename = positiveSamplesFilenameList.pop()\n",
    "        src = os.path.join(unsortedPositiveSamplesDir, filename)\n",
    "        dst = os.path.join(valPositiveDir, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for _ in range(math.floor(numValSamples*(1. - positiveRatio))):\n",
    "        filename = negativeSamplesFilenameList.pop()\n",
    "        src = os.path.join(unsortedNegativeSamplesDir, filename)\n",
    "        dst = os.path.join(valNegativeDir, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "else:\n",
    "    raise Exception(\"Sorted image directories are not empty.\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b820981-9e6d-452e-8c2a-87527c8a67b7",
   "metadata": {},
   "source": [
    "[*Optional*]: Test whether a sample handful of the images were copied to the correct folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbcc446d-f176-4b97-810a-cf7d7883aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "runImageCopyTest = False\n",
    "\n",
    "comparisonSampleSize = 50\n",
    "imageFiletype = 'png'\n",
    "##\n",
    "\n",
    "if runImageCopyTest:\n",
    "    # These must be redefined here since they were popped\n",
    "    positiveSamplesFilenameList = os.listdir(unsortedPositiveSamplesDir)\n",
    "    negativeSamplesFilenameList = os.listdir(unsortedNegativeSamplesDir)\n",
    "\n",
    "    sortedTrainPositiveFilenameList = os.listdir(trainPositiveDir)\n",
    "    sortedTrainNegativeFilenameList = os.listdir(trainNegativeDir)\n",
    "    sortedTestPositiveFilenameList = os.listdir(testPositiveDir)\n",
    "    sortedTestNegativeFilenameList = os.listdir(testNegativeDir)\n",
    "    sortedValPositiveFilenameList = os.listdir(valPositiveDir)\n",
    "    sortedValNegativeFilenameList = os.listdir(valNegativeDir)\n",
    "    random.shuffle(sortedTrainPositiveFilenameList)\n",
    "    random.shuffle(sortedTrainNegativeFilenameList)\n",
    "    random.shuffle(sortedTestPositiveFilenameList)\n",
    "    random.shuffle(sortedTestNegativeFilenameList)\n",
    "    random.shuffle(sortedValPositiveFilenameList)\n",
    "    random.shuffle(sortedValNegativeFilenameList)\n",
    "\n",
    "    allPositiveFilenameLists = [sortedTrainPositiveFilenameList, sortedTestPositiveFilenameList, sortedValPositiveFilenameList]\n",
    "    allNegativeFilenameLists = [sortedTrainNegativeFilenameList, sortedTestNegativeFilenameList, sortedValNegativeFilenameList]\n",
    "\n",
    "    def matchesImageFiletype(sampleFilename : str, imageFiletype : str): # Needed to ignore straggler files such as notebook checkpoints\n",
    "        return sampleFilename[:len(imageFiletype)] == imageFiletype\n",
    "\n",
    "    for fList in allPositiveFilenameLists:\n",
    "        assert(all(sampleFilename in positiveSamplesFilenameList\n",
    "                   for sampleFilename in fList[:comparisonSampleSize]\n",
    "                   if matchesImageFiletype(sampleFilename, imageFiletype)))\n",
    "    for fList in allNegativeFilenameLists:\n",
    "        assert(all(sampleFilename in negativeSamplesFilenameList\n",
    "                   for sampleFilename in fList[:comparisonSampleSize]\n",
    "                   if matchesImageFiletype(sampleFilename, imageFiletype)))\n",
    "    print('Test was succesful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c43ac-71fa-40e3-b850-d0a924b2bd75",
   "metadata": {},
   "source": [
    "### 1.3 Data generators\n",
    "\n",
    "The data generators themselves can rescale the input pixel values to the [0, 1] range. Note that the pretrained baseline models expect certain kinds of input - Respectively, EfficientNet excepts pixel floats in the [0-255] range to be passed through the keras.applications.resnet_v2.preprocess_input() function, and ResNet expects its input to be raw, which will have its pixel values rescaled to the (-1, 1) range. Thus, a seperate set of data generators are made for them which do net rescale their input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812df1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2121 images belonging to 2 classes.\n",
      "Found 706 images belonging to 2 classes.\n",
      "Found 724 images belonging to 2 classes.\n",
      "Found 2121 images belonging to 2 classes.\n",
      "Found 706 images belonging to 2 classes.\n",
      "Found 724 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "batchSize = 75\n",
    "##\n",
    "\n",
    "trainDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "testDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "valDataGenerator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "trainDataGenerator = trainDataGeneratorFactory.flow_from_directory( # Batch generator\n",
    "    trainDir,\n",
    "    target_size = (150, 150), # TODO: What size do I want?\n",
    "    batch_size = batchSize,\n",
    "    class_mode = 'binary')\n",
    "testDataGenerator = testDataGeneratorFactory.flow_from_directory(\n",
    "    testDir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = batchSize,\n",
    "    class_mode = 'binary')\n",
    "valDataGenerator = testDataGeneratorFactory.flow_from_directory(\n",
    "    valDir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = batchSize,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "baselineTrainDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator()\n",
    "baselineTestDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator()\n",
    "baselineValDataGeneratorFactory = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "baselineTrainDataGenerator = baselineTrainDataGeneratorFactory.flow_from_directory( # Batch generator\n",
    "    trainDir,\n",
    "    target_size = (150, 150), # TODO: What size do I want?\n",
    "    batch_size = batchSize,\n",
    "    class_mode = 'binary')\n",
    "baselineTestDataGenerator = baselineTestDataGeneratorFactory.flow_from_directory(\n",
    "    testDir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = batchSize,\n",
    "    class_mode = 'binary')\n",
    "baselineValDataGenerator = baselineValDataGeneratorFactory.flow_from_directory(\n",
    "    valDir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = batchSize,\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16640509-5c84-4ce2-875b-efc0b1282497",
   "metadata": {},
   "source": [
    "## 2 Baseline model implementation\n",
    "Two pretrained models, EfficientNet and ResNet, will be implemented and tested as baselines. They will be implemented both as feature extractors (i.e. outputting their feature maps for a seperate model) and with retrained top-layer classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9c6cc-38d9-4389-bd9a-a6d66f6d94b3",
   "metadata": {},
   "source": [
    "### 2.1 Implementation of untuned but pretrained EfficientNet and ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a878253-c77a-43a5-802a-b7237f60d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTHER IDEA: Try a baseline model trained on MNIST\n",
    "\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#print(f'Using {device}.')\n",
    "\n",
    "#torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_widese_b0', pretrained=True')\n",
    "\n",
    "efficientNetB0Base = keras.applications.efficientnet.EfficientNetB0(\n",
    "    include_top = False,\n",
    "    input_shape = (150, 150, 3), # Input to pretrained model must have 3 channels\n",
    "    weights = 'imagenet')\n",
    "    #pooling = 'avg')\n",
    "resNet50V2Base = keras.applications.resnet_v2.ResNet50V2(\n",
    "    include_top = False,\n",
    "    input_shape = (150, 150, 3), # Input to pretrained model must have 3 channels\n",
    "    weights = 'imagenet')\n",
    "    #pooling = 'avg')\n",
    "\n",
    "efficientNetB0Base.trainable = False\n",
    "resNet50V2Base.trainable = False\n",
    "\n",
    "#efficientNetB0 = models.Sequential(name = 'efficientNetB0')\n",
    "#efficientNetB0.add(tf.keras.layers.Conv2D(16, 7, strides = 3, padding = 'same'/'valid', activation=\"relu\", trainable=True))\n",
    "\n",
    "# TODO: The default final output is of shape 5x5x1280. I need to figure out how to downscale that into a single softmax output.\n",
    "\n",
    "# keras.applications.resnet_v2.preprocess_input()\n",
    "# When exactly should this be implemented?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9047a29d-b122-44ec-b826-59f68d205622",
   "metadata": {},
   "source": [
    "### 2.2 Feature extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91db39f8-cf59-4120-b15c-b9b4574f577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(model, generator, modelOutputShape:tuple, numSamples=None):\n",
    "    if not numSamples:\n",
    "        numSamples = generator.n\n",
    "    if numSamples % batchSize != 0:\n",
    "        numSamples -= (numSamples % batchSize)\n",
    "    features = np.zeros(shape=(numSamples, *modelOutputShape)) # 5 5 1280\n",
    "    labels = np.zeros(shape=(numSamples))\n",
    "    i = 0\n",
    "    for inputBatch, labelBatch in generator:\n",
    "        featureBatch = model.predict(inputBatch)\n",
    "        features[i*batchSize : (i + 1)*batchSize] = featureBatch\n",
    "        labels[i*batchSize : (i + 1)*batchSize] = labelBatch\n",
    "        i += 1\n",
    "        if i*batchSize >= numSamples:\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666a057-ace4-4ef7-8cf9-19ee08c7f8d1",
   "metadata": {},
   "source": [
    "### 2.3 EfficientNet as feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5417e646-9746-466e-93a9-c4a8842d08f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNetTrainFeatures, efficientNetTrainLabels = extractFeatures(efficientNetB0Base, baselineTrainDataGenerator, (5, 5, 1280))\n",
    "efficientNetTestFeatures, efficientNetTestLabels = extractFeatures(efficientNetB0Base, baselineTestDataGenerator, (5, 5, 1280))\n",
    "efficientNetValFeatures, efficientValTestLabels = extractFeatures(efficientNetB0Base, baselineValDataGenerator, (5, 5, 1280))\n",
    "\n",
    "efficientNetTrainFeatures = efficientNetTrainFeatures.flatten()\n",
    "efficientNetTestFeatures = efficientNetTestFeatures.flatten()\n",
    "efficientNetValFeatures = efficientNetValFeatures.flatten()\n",
    "\n",
    "flatFeatureSize = efficientNetTrainFeatures.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcb5ce0c-b0d1-409a-a350-aba222b316ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flatFeatureSize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m efficientNetB0FEClassifier \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m----> 2\u001b[0m efficientNetB0FEClassifier\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_dim\u001b[38;5;241m=\u001b[39m\u001b[43mflatFeatureSize\u001b[49m))\n\u001b[0;32m      3\u001b[0m efficientNetB0FEClassifier\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.5\u001b[39m))\n\u001b[0;32m      4\u001b[0m efficientNetB0FEClassifier\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'flatFeatureSize' is not defined"
     ]
    }
   ],
   "source": [
    "efficientNetB0FEClassifier = keras.models.Sequential()\n",
    "efficientNetB0FEClassifier.add(keras.layers.Dense(256, activation='relu', input_dim=flatFeatureSize))\n",
    "efficientNetB0FEClassifier.add(keras.layers.Dropout(0.5))\n",
    "efficientNetB0FEClassifier.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "efficientNetB0FEClassifier.compile(optimizer=tfa.optimizers.Yogi,\n",
    "                                  loss='binary_crossentropy',\n",
    "                                  metrics=['binary_accuracy', 'binary_crossentropy', 'auc', 'precision', 'recall', 'f1'])\n",
    "efficientNetB0FEClassifierHistory = efficientNetB0FEClassifier.fit(efficientNetTrainFeatures, efficientNetTrainLabels,\n",
    "                                                                   epochs=30,\n",
    "                                                                   batch_size=75,\n",
    "                                                                   validation_data=(efficientNetTrainValFeatures, efficientNetTrainValLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae21dfa6-4d49-4f2f-b6e1-0ec27fd24667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "crossEntropy, valCrossEntropy, auc, valAuc, precision, valPrecision, recall, valRecall, f1, valF1 = \\\n",
    "efficientNetB0FEClassifierHistory.history[('binary_crossentropy', 'val_binary_crossentropy', 'auc', 'val_auc', 'precision', 'val_precision', 'recall',\n",
    "                                   'val_recall', 'f1', 'val_f1')]\n",
    "epochs = range(1, len(crossEntropy) + 1)\n",
    "\n",
    "plt.plot(epochs, crossEntropy, 'bo', label='Training Cross-Entropy')\n",
    "plt.plot(epochs, valCrossEntropy, 'b', label='Validation Cross-Entropy')\n",
    "plt.title('Training and validation cross-entropy for EfficientNet feature extraction')\n",
    "plt.legend()\n",
    "plt.savefig('EfficientNetFEXEntropy.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, auc, 'bo', label='Training AUC')\n",
    "plt.plot(epochs, valAuc, 'b', label='Validation AUC')\n",
    "plt.title('Training and validation AUC for EfficientNet feature extraction')\n",
    "plt.legend()\n",
    "plt.savefig('EfficientNetFEAUC.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, precision, 'bo', label='Training Precision')\n",
    "plt.plot(epochs, valPrecision, 'b', label='Validation Precision')\n",
    "plt.title('Training and validation precision for EfficientNet feature extraction')\n",
    "plt.legend()\n",
    "plt.savefig('EfficientNetFEPrecision.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, recall, 'bo', label='Training Recall')\n",
    "plt.plot(epochs, valRecall, 'b', label='Validation Recall')\n",
    "plt.title('Training and validation recall for EfficientNet feature extraction')\n",
    "plt.legend()\n",
    "plt.savefig('EfficientNetFERecall.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, f1, 'bo', label='Training F1-score')\n",
    "plt.plot(epochs, valF1, 'b', label='Validation F1-score')\n",
    "plt.title('Training and validation F1-score for EfficientNet feature extraction')\n",
    "plt.legend()\n",
    "plt.savefig('EfficientNetFEF1.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dataScience] *",
   "language": "python",
   "name": "conda-env-dataScience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
